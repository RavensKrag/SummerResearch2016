# encoding: utf-8

require 'rubygems'

require 'rake'
require 'rake/clean'
require 'rake/testtask'

require 'bundler'
Bundler.require(:default)
require 'bundler/setup'

# other libraries
require 'yaml'
require 'csv'
require 'set'
require 'open-uri'
require 'csv'

# constants
PATH_TO_FILE = File.expand_path(File.dirname(__FILE__))

# -- file hierarchy --
		# ROOT
		# 	this directory
		# 		this file

# Must expand '..' shortcut into a proper path. But that results in a shorter string.
PATH_TO_ROOT = File.expand_path '../..', __FILE__


# files
Dir.chdir PATH_TO_ROOT do
	require_all './lib/SummerResearch'
end



# setup tests
Rake::TestTask.new do |t|
	t.libs = []
	t.test_files = FileList['test/test*.rb']
	t.verbose = true
end

# task :default => :run











# Run multiple pathways with a single command
# usage: rake pathways[1,2,3]
# 
#           positional arguments only, no named args
#               V
task :pathways, [] => [:load_dependencies, :setup_data] do |t, args|
	pathway_numbers = args.extras.collect{|x| x.to_i }
	
	puts "pathways: #{pathway_numbers.inspect}"
	
	pathway_numbers.each do |number|
		Rake::Task["pathway#{number}".to_sym].invoke()
	end
end




# ok, this is pretty solid...
# but what happens when you get mulitple intermediates out of one process?
# (similar to a multiple return)


# Check out this question on StackOverflow that deals with this exact situation:
# src: http://stackoverflow.com/questions/24026092/rake-task-with-multiple-prerequisites-generating-multiple-outputs

# I modified that a little bit to write #multi_file()

# Declare a file task that generates mulitple files with the same prerequisites.
# (actually will generate multiple tasks, but this is a nice convienence)
def multi_file(args={}, &block)
	# kinda a hacky way of getting the Rake-style interface.
	# Should probably see what Rake actually does,
	# because this is not sophisticated enough to be how Rails works.
	outputs        = args.keys.first
	shared_prereqs = args.values.first
	
	outputs.each do |filename|
		file filename => shared_prereqs do |t|
			block.call(t)
		end
		# there should be a way to just pass the block, instead of calling a block from a block
		# but that way is complicated and arcane, so don't do it.
		# 
		# This way is simple to understand.
	end
end

# multi_file %w[target1.txt target2.txt] => %w[src1.txt src2.txt] do
	
# end





# =============================================





# could pull down *list* of all courses associated with a dept
# if courses in a major have prereqs in that department?
# (definitely don't actually pull down each and every course before filtering though...)

# under the current pipeline, I think this is the only way to do things?
# can't ask for a single class by course ID until you have a list of all courses by dept
# (foo4 experiments with this, but currently does not except a parameter)

# department_codes = better_list.collect{ |course| course.id.split(' ').first }.uniq



# ^ old way of doing things.
# The current implementation of Catalog first scans all years
# for a particular set of dept codes.
# 
# It will figure out what the urls are for all classes within this set,
# but refrain from downloading any specific course information
# until that particular class is requested.
# 
# It will cache data for specific courses in MongoDB,
# and save dept / id / url information in SQLite







# how to start and run MongoDB:
	# https://docs.mongodb.com/manual/tutorial/manage-mongodb-processes/
mongo_db_storage_path = File.expand_path("bin/data/mongo",          PATH_TO_ROOT)
mongo_db_logpath      = File.expand_path("bin/data/mongo_logs/log", PATH_TO_ROOT)

puts "========="
puts "Start up mongo in another terminal with the following command:"
puts "mongod --dbpath '#{mongo_db_storage_path}' --port 12345"

puts "and if necessary, mongo can be stopped with this command:"
puts "mongod --dbpath '#{mongo_db_storage_path}' --port 12345 --shutdown"
puts "========="
# (needs to know just the dbpath so it knows what DB to stop, but may as well pass everything)


# launch mongo as a daemon
		# mongod --fork --logpath /var/log/mongodb.log





SQLITE_DATABASE_FILEPATH = 'data/example.db'


task :create_db => SQLITE_DATABASE_FILEPATH

file SQLITE_DATABASE_FILEPATH do
	@catalog = SummerResearch::Catalog.new(SQLITE_DATABASE_FILEPATH)
		# connect to the SQLite and MongoDB databases
		
	@catalog.setup
		# establish the schema
	@catalog.fetch_course_listing
		# download list of possible catalog years
		# figure out how to search by dept code for each and every catalog year
		# get lists of courses, based on a subset of dept codes, for each and every year
end

# file SQLITE_DATABASE_FILEPATH do
# 	Rake::Task["db_backend:create_db"].invoke
# end

# run 'create_db' before this to download initial data
# (can't list as explict dependency at this time, because I don't know how to easily skip processing an entire catalog year)
task :query_db => [SQLITE_DATABASE_FILEPATH] do
	@catalog = SummerResearch::Catalog.new(SQLITE_DATABASE_FILEPATH)
	
	
	info = @catalog.course_info('CS 101')
	p info
	# @catalog.query do |q|
		
	# end
end

task :wipe_mongo => [SQLITE_DATABASE_FILEPATH] do
	@catalog = SummerResearch::Catalog.new(SQLITE_DATABASE_FILEPATH)
	
	@catalog.course_details_mongo do |db|
		result = db.delete_many
		puts result.n
	end
end


namespace :fetch_all do
	task :populate_index => SQLITE_DATABASE_FILEPATH
	file SQLITE_DATABASE_FILEPATH do
		@catalog = SummerResearch::Catalog.new(SQLITE_DATABASE_FILEPATH)
		
		@catalog.fetch_full_index()
		# START: 10:32 PM, Aug 1, 2016
		# END:   11:28 PM, Aug 1, 2016
	end
	
	
	
	# fetch all of the data in the catalog, and put it into a Mongo database
	task :populate_mongo_db => SQLITE_DATABASE_FILEPATH do
		# START: 11:32 PM, Aug 1, 2016
		# END:    1:15 AM  Aug 2 (incomplete. ~2 years worth of data. stopped a couple times)
		
		filepath = File.expand_path(
			'./all_fetch_logfile.txt',
			SummerResearch::Utilities::DATA_DIR
		)
		
		
		@catalog = SummerResearch::Catalog.new(SQLITE_DATABASE_FILEPATH)
		
		@catalog.activerecord_query do |course_model, catologyear_model|
			catologyear_model.all.order("year_range DESC").each do |year_record|
				File.open(filepath, 'a') do |f|
					f.puts year_record.inspect
				end
				
				
				all_courses_in_year = 
					year_record.courses
					           .order(:dept)
					           .reject{|course| course.dept == "Mason Core"}
				
				# --- Try to fetch information for all courses in the desired set.
				#     If you can't process a course, just keep going, but log some error data.
				#     This error log can be examined later to determine new CatalogInfo Types.
				# TODO: would be nice if you could have some sort of progress indicator for this.
					
				all_courses_in_year.each do |course_record|			
					begin
						@catalog.fetch_course_info(course_record)
					rescue StandardError => e
						File.open(filepath, 'a') do |f|
							f.puts "course id:   #{course_record.course_id}"
							# TODO: Add short description to index
							# f.puts "description: #{course.description}"
							f.puts "url:         #{course_record.url}"
							
							# output the data from the exception
							# (the program will still continue to run)
							# (resulting in all errors printed in one place)
							f.puts e.message
							e.backtrace.each do |line|
								f.puts "\t" + line
								# indent the lines of the backtrace.
								# makes it easier to see things when you start getting multiple errors
							end
							f.puts "=============="
							f.puts
							f.puts
						end
					end
				end
			end
		end
	end
end

task :get_info do
	@catalog = SummerResearch::Catalog.new(SQLITE_DATABASE_FILEPATH)
	p @catalog.course_info("STAT 344")
end










# search for relevant programs of study
# 'list_of_degrees' specifies a list of keywords to search for.
# All relevant programs of study will be outputted to
# the 'programs_of_study.yaml' file in the data directory
file 'data/programs_of_study.yaml' do
	puts "=== setup data"
	
	list_of_degrees = [
		"Computer Science",
		"Information Technology",
		"Electrical Engineering",
		"Biology",
		"Psychology"
	]
	
	degrees = SummerResearch.search_programs_of_study(list_of_degrees)
	
	
	count = degrees.keys.size
	puts "#{count} programs found for search query."
	
	SummerResearch::Utilities.write_to_file("./programs_of_study.yaml", degrees.to_yaml)
	@programs_of_study = degrees
end
















# TODO: reimplement these tests calling actual code from Catalog
# maybe use instance_eval? probably need to break up the code in Catalog a little better, to allow for testing without having to just copy the code over like this
namespace :catalog_test do
	# all of these tests use the 2016-2017 catalog year, catoid = "29"
	
	task 'data/CS_course_list.html' do
		# little bit of code to get the page where the CS courses 
		# copied from Catalog#search_by_department()
		catoid, navoid, dept_code = %w[29 6272 CS]
		
		url = "http://catalog.gmu.edu/content.php?filter%5B27%5D=#{dept_code}&filter%5B29%5D=&filter%5Bcourse_type%5D=-1&filter%5Bkeyword%5D=&filter%5B32%5D=1&filter%5Bcpage%5D=1&cur_cat_oid=#{catoid}&expand=&navoid=#{navoid}&search_database=Filter#acalog_template_course_filter"
		
		xml = Nokogiri::HTML(open(url))
		
		
		# cache data on the disk
		SummerResearch::Utilities.write_to_file("./CS_course_list.html", xml)
	end
	
	task :multiple_page_iteration => 'data/CS_course_list.html' do
		filepath = File.expand_path("./CS_course_list.html", SummerResearch::Utilities::DATA_DIR)
		xml = Nokogiri::HTML(open(filepath))
		
		links = CatalogTest.page_links(xml)
		
		puts links
		pages = links.collect{  |url|  Nokogiri::HTML(open(url))  }
		
		
		# add the original page to the set of all pages
		pages.unshift(xml)
		
		
		# === Get all links from each and every page
		data = 
			pages.collect do |xml|
				# === copied from Catalog#search_by_department()
				
				node = xml.css('td.block_content_outer table')[3]
					# SummerResearch::Utilities.write_to_file("./search.html", xml) if node.nil?
				# NOTE: sometimes fails to find courses.
				# just retry the request again, and you should be able to get it.
				while node.nil?
					puts "nope. wait a sec..."
					sleep(3.0) # wait a bit before retrying
					puts "retrying #{dept_code}..."
					
					xml = Nokogiri::HTML(open(url))
					node = xml.css('td.block_content_outer table')[3]
				end
				
				
				# NOTE: results are paginated. Should get info from ALL pages, not just the first one.
				
				tr_list = node.css('tr')[2..-1]
				
				# tr_list.each{|x| puts x.class }
				tr_list.collect{  |x| SummerResearch.get_all_weird_link_urls(x)  }.flatten
			end
		
		# === Show the courses gathered from the links
		puts data.flatten.collect{  |catalog_link|  catalog_link.id  }
	end
	
	
	# show the page counts for various degrees in the catalog
	task :page_counts do
		departments_with_999 = %w[ASTR BIOD BENG BINF BIOS CHEM CEIE CLIM COMM CSI CSS CS CONF CRIM CULT ECON EDUC ECE ENGH EVPP GGS GOVT HAP HE HIST IT LING MATH MUSI NEUR NURS PSCI PHYS PSYC PUBP RHBS SOCI STAT SEOR]
		
		# department_codes = departments_with_999
		department_codes = CatalogTest.all_department_codes()
		
		department_codes.each do |dept_code|
			# little bit of code to get the page where the CS courses 
			# copied from Catalog#search_by_department()
			catoid, navoid = %w[29 6272]
			
			url = "http://catalog.gmu.edu/content.php?filter%5B27%5D=#{dept_code}&filter%5B29%5D=&filter%5Bcourse_type%5D=-1&filter%5Bkeyword%5D=&filter%5B32%5D=1&filter%5Bcpage%5D=1&cur_cat_oid=#{catoid}&expand=&navoid=#{navoid}&search_database=Filter#acalog_template_course_filter"
			
			xml = Nokogiri::HTML(open(url))
			
			
			
			
			
			# copied from :multiple_page_iteration task above
			links = CatalogTest.page_links(xml)
			page_count = links.length + 1
			
			puts page_count
			# need to add 1 to page count, because there is no link to the current page, ie the first page
			
			
			
			
			# query all dept codes at once to see how many pages will fit before elipsis is inserted
			# http://catalog.gmu.edu/content.php?filter%5B27%5D=-1&filter%5B29%5D=&filter%5Bcourse_type%5D=-1&filter%5Bkeyword%5D=&filter%5B32%5D=1&filter%5Bcpage%5D=1&cur_cat_oid=29&expand=&navoid=6272&search_database=Filter#acalog_template_course_filter
			# 
			# => as long as there are 11 or fewer pages,
			#    should be able to traverse without any problems
			
			
			# can easily chuck the numbers that get printed into a histogram for easy viewing
			# http://www.shodor.org/interactivate/activities/Histogram/
			# => 1 page  => 140
			#    2 pages => ~20
			#    3 pages => a couple
		end
	end	
end
module CatalogTest
	class << self
		def all_department_codes
			# === copied from Catalog#fetch_course_listing()
			catoid         = "29"
			courses_navoid = "6272"
			url = "http://catalog.gmu.edu/content.php?catoid=#{catoid}&navoid=#{courses_navoid}"
			
			
			# === copied from Catalog#all_department_codes()
			xml = Nokogiri::HTML(open(url))
			
			#course_search > table > tbody > tr:nth-child(4) > td:nth-child(1) > select
			segment = xml.css('#course_search table tr:nth-child(4) > td:nth-child(1) > select > option')
				# Utilities.write_to_file("./department_codes_fragment.html", segment)
			
			departments = segment.collect{  |option_node|  option_node["value"]  } 
			departments.shift # remove the first one, which is just -1, the default nonsense value
			
			return departments
		end
		
		def page_links(nokogiri_html)
			fragment = nokogiri_html.css('td.block_content_outer table')
			page_navigation = fragment.css('td').last
			
			# puts page_navigation
			
			
			relative_links = page_navigation.xpath('a/@href')
			links          = relative_links.collect{  |x| "http://catalog.gmu.edu" + x.value  }
			
			return links
		end
	end
end



# NOTE: this method does not work. this is just a rough sketch
def all_courses_for_degree(url_to_program_requirements_page)
	puts "=== run processing"
	
	# === take one degree program, and walk the dependencies for all courses in the degree
	# (get all relevant courses)
	
	fragment = SummerResearch.requirements_subtree(url_to_program_requirements_page)
	
	# TODO: need to improve this selector. catching some false positives.
	# wait, variable 'fragment' is a list...
	course_list = SummerResearch.get_all_weird_link_urls(fragment)
	
	
	
	
	# TODO: remove dupicate entries in the list of courses
		# not just as simple as removing duplicates from list
		# need to remove when two tuples have the same first element
		# also - want to keep original ordering
	# NOTE: this may not be necessary if the selection filter on links is improved
	
	
	return course_list
end


task :restricted_set_size do
	@catalog = SummerResearch::Catalog.new(SQLITE_DATABASE_FILEPATH)
	
	
	
	@catalog.activerecord_query do |course_model, catologyear_model|
		count =
			SummerResearch::Catalog::CASE_STUDY_DEPARTMENT_SET
				.collect{  |dept|
					course_model.where(:dept => dept).size
				}
				.reduce(&:+)
		
		puts "Count of all courses in the case study department set: #{count}"
	end
	
	
	# @catalog.mongo_query :course_info do |mongo|
	# 	
	# 	mongo.find(
	# 		:course_id => record.course_id
	# 	)
	# end
	
	
	
	
	
	puts "=== load data..."
	@programs_of_study ||= YAML.load_file("data/programs_of_study.yaml")
	
	
	puts "=== cycle through programs of study..."
	
	programs = [
		"Computer Science, BS",
		"Applied Computer Science, BS",
		"Biology, BA",
		"Biology, BS",
		"Psychology, BA"
	]
	programs.each do |degree_name|
		puts "=== Getting info for: #{degree_name}"
		url = @programs_of_study[degree_name]
		courses = all_courses_for_degree(url)
		# If the program list has a weird link in it, then the foo2 will fail before reaching the end of the list
			# url = @env.degrees[degree_name]
			# course_list = SummerResearch.degree_requirements(url)
			# puts "test"
		# failure occurs inside of SummerResearch.degree_requiremnts
		
		
		
		p courses.size
		# => 474 total courses across all degrees being studied, assuming no overlap (which is probably wrong)
	end
end



# ==================
# v  tests, based on old pathways


# === test conversion of CatalogLink object => CourseInfo object
# (NOTICE: this is not a unit test, just a bunch of diagnostics)
# Used for fetching detailed information on a specific course from the catalog.
# Currently does not save documents in Mongo DB.
# 
# There are currently 3 different major types of document pages stored in the online catalog
# CourseInfo should be able to parse all of the differnt variations.
# These tests throw a considerable variety of data at CourseInfo, and print diagonstics.
# 
# Viewing the diagnostic outputs from these tasks should help a person see
# how the system currently is classifying these documents.
# (NOTE: this is a manually designed and implemented classification, not machine learning)
task :test_course_info_fetch => [:one_degree, :debug, :debug_verbose, :all_degrees_debug]
namespace :test_course_info_fetch do
	task :sample_data do
		# NOTE: easily get data for this table from the intermediate file required_courses.csv
		# (UPDATE: need to figure out a similarly easy way to rip this data out from the DB)
		
		# NOTE: not all courses specify all attributes. 
		#   ex) If there are no corequisites, the field is omitted
		sample = [
			[
				"CS 101",
				"Preview of Computer Science",
				"http://catalog.gmu.edu/preview_course.php?catoid=29&coid=302776&print"
			],
			[
				"CS 465",
				"Computer Systems Architecture",
				"http://catalog.gmu.edu/preview_course.php?catoid=29&coid=302800&print"
			],
			[
				"CS 475",
				"Concurrent and Distributed Systems",
				"http://catalog.gmu.edu/preview_course.php?catoid=29&coid=302803&print"
			],
			[
				"CS 330",
				"Formal Methods and Models",
				"http://catalog.gmu.edu/preview_course.php?catoid=29&coid=302788&print"
			],
			[
				"STAT 344",
				"Probability and Statistics for Engineers and Scientists I",
				"http://catalog.gmu.edu/preview_course.php?catoid=29&coid=306778&print"
			],
			[
				"PSYC 320",
				"Psychological Tests and Measurements",
				"http://catalog.gmu.edu/preview_course.php?catoid=29&coid=306130&print"
			],
			[
				"EVPP 110", # 'sustainable mason' badge
				"The Ecosphere: An Introduction to Environmental Science I",
				"http://catalog.gmu.edu/preview_course.php?catoid=29&coid=303982&print"
			],
			[
				"GGS 103",  # 'sustainable mason' badge
				"Human Geography",
				"http://catalog.gmu.edu/preview_course.php?catoid=29&coid=304295"
			],
			[
				"Mason Core UGU",
				"Global Understanding",
				"http://catalog.gmu.edu/preview_course.php?catoid=29&coid=308635"
			],
			
			
			[
				"OM 210",
				"Statistical Analysis for Management",
				"http://catalog.gmu.edu/preview_course.php?catoid=29&coid=305751"
			],
			[
				"OR 574",
				"Quality Control and Process Management",
				"http://catalog.gmu.edu/preview_course.php?catoid=29&coid=305770"
			],
			[
				"CEIE 450",
				"Environmental Engineering Systems",
				"http://catalog.gmu.edu/preview_course.php?catoid=29&coid=302280"
			],
			[
				"CLIM 102",
				"Introduction to Global Climate Change Science",
				"http://catalog.gmu.edu/preview_course.php?catoid=29&coid=307948"
			],
			[
				"SOM 301",
				"Business Models: A Communication Approach",
				"http://catalog.gmu.edu/preview_course.php?catoid=29&coid=306669"
			],
			[
				"CEIE 501",
				"Sustainable Development",
				"http://catalog.gmu.edu/preview_course.php?catoid=29&coid=302288"
			],
			[
				"REAL 796",
				"Directed Reading",
				"http://catalog.gmu.edu/preview_course.php?catoid=29&coid=306438"
			],
			[
				"MATH 551",
				"Regression and Time Series",
				"http://catalog.gmu.edu/preview_course.php?catoid=29&coid=305092"
			],
			[
				"MLSC 302",
				"Applied Leadership II",
				"http://catalog.gmu.edu/preview_course.php?catoid=29&coid=307989"
			],
			[
				"PHYS 440",
				"Nuclear and Particle Physics",
				"http://catalog.gmu.edu/preview_course.php?catoid=29&coid=305999"
			]
		].collect{|a,b,c| SummerResearch::CatalogLink.new(a, b, c, 'manual') }
		
		# TODO: figure out what the anatomy of a course is
		# * CS 101
		# * Preview of Computer Science
		# * Description
		# * Section ID?
		# --- these are all different things


		# TODO: if department is not found, error should alert the user that list of courses needs to be pulled down from the Catalog for that department before asking for a course.
		
		@pw_sample = sample
	end
	
	
	
	# [CatalogLink] => [CourseInfo] DEBUG
	# only shows error messages when the system fails to fetch a page
	# otherwise just prints dots to let you know progress is happening
	# allows you to see errors across all entries (does not stop after the first error)
	# 
	# (input dataset: sample dataset)
	task :debug => [:sample_data] do
		@catalog = SummerResearch::Catalog.new(SQLITE_DATABASE_FILEPATH)
		
		puts "=== run processing"
		
		# @pw_sample --> course_data
		# 
		# sample data set => [CatalogLink] 
		# [CatalogLink] => [CourseInfo] DEBUG
		course_data = CourseInfoDiagnostic.debug(@catalog, @pw_sample) 
	end
	
	# [CatalogLink] => [CourseInfo] DEBUG VERBOSE
	# prints extensive information on the types of data being detected.
	# type signatures and debug information displayed for all entries.
	# allows you to see errors across all entries (does not stop after the first error)
	# 
	# (input dataset: sample dataset)
	task :debug_verbose => [:sample_data] do
		@catalog = SummerResearch::Catalog.new(SQLITE_DATABASE_FILEPATH)
		
		puts "=== run processing"
		
		# @pw_sample --> course_data
		# 
		# sample data set => [CatalogLink] 
		# [CatalogLink] => [CourseInfo] DEBUG VERBOSE
		course_data = CourseInfoDiagnostic.debug_verbose(@catalog, @pw_sample)
	end
	
	
	# course [CatalogLink] => [CourseInfo] DEBUG
	# no debug information. just prints the course ids for the classes being downloaded
	# (input dataset: all courses from CS degree)
	task :one_degree_debug => "data/programs_of_study.yaml" do
		@programs_of_study ||= YAML.load_file("data/programs_of_study.yaml")
		
		@catalog = SummerResearch::Catalog.new(SQLITE_DATABASE_FILEPATH)
		
		
		
		programs = [
			"Computer Science, BS",
			"Applied Computer Science, BS",
			"Biology, BA",
			"Biology, BS",
			"Psychology, BA"
		]
		
		program_name = "Computer Science, BS"
		url = @programs_of_study[program_name]
		courses = all_courses_for_degree(url)
		
		
		
		
		puts "=== run processing"
		course_data = CourseInfoDiagnostic.debug(@catalog, courses) # course [CatalogLink] => [CourseInfo] RELEASE VERSION
		
		SummerResearch::Utilities.write_to_file('./course_info.yaml', course_data.to_yaml)
	end
	
	# [CatalogLink] => [CourseInfo] DEBUG
	# (input dataset: ALL courses from ALL majors in the sample set)
	# 
	# same core procedure as pw6, but with a much bigger data set
	task :all_degrees_debug do
		@catalog = SummerResearch::Catalog.new(SQLITE_DATABASE_FILEPATH)
		
		puts "=== load data..."
		@programs_of_study ||= YAML.load_file("data/programs_of_study.yaml")
		
		
		puts "=== cycle through programs of study..."
		
		programs = [
			"Computer Science, BS",
			"Applied Computer Science, BS",
			"Biology, BA",
			"Biology, BS",
			"Psychology, BA"
		]
		programs.each do |degree_name|
			puts "=== Getting info for: #{degree_name}"
			url = @programs_of_study[degree_name]
			courses = all_courses_for_degree(url)
			# If the program list has a weird link in it, then the foo2 will fail before reaching the end of the list
				# url = @env.degrees[degree_name]
				# course_list = SummerResearch.degree_requirements(url)
				# puts "test"
			# failure occurs inside of SummerResearch.degree_requiremnts
			
			puts "=== analyzing courses... "
			course_data = CourseInfoDiagnostic.debug(@catalog, courses)
		end
		
		# errors from: SummerResearch::CourseInfo#fetch
		# two other page formats:
			# +  new page format: attemps to give more structure using <p> to separate into sub-regions, but actually malformed
				# ^ seems to be for more recent courses? not really sure why the markup is different
			# +  Mason Core pages: Totally different pages, because these are not actually courses. They are "aliases" of sorts for entire lists of courses.
		
		
		
		# NOTE: perhaps not all majors work right now? so be careful of that too
		
		
		
		# NOTE: the following programs of study only use Type A or Type B catalog links
			# "Computer Science, BS",
			# "Biology, BA",
		# NOTE: the following programs of study are known to list courses with Type C catalog links
			# "Applied Computer Science, BS",
			# "Biology, BS",
			# "Psychology, BA"
	end
	
	
	task :extended_set => "data/all_courses_2016_anomalies.txt" do
		# ASSUME: requires that you load up ALL COURSES for the current catalog year, as was done when generating Qian Hu's dataset. Not going to copy that code here, just assuming it has been done already.
			# (This only uses the index data, it should not use data from Mongo)
		@catalog = SummerResearch::Catalog.new(SQLITE_DATABASE_FILEPATH)
		
		
		# read from file
		filepath = File.expand_path(
			"./all_courses_2016_anomalies.txt",
			SummerResearch::Utilities::DATA_DIR
		)
		data = File.readlines(filepath)
		
		# chunk the data
		chunk_size = 3
		number_of_records = 98
		data = data.collect{ |line| line.chomp }
		           .each_slice(chunk_size).to_a
		data.pop() # remove the last entry
		
		data.each{|list| list.pop } # remove the last line of each cluster, which is just empty
		
		p data.last(3)
		
		data.collect! do |course_id, url|
			# remove the part at the beginning of the line that explains what this field is
			course_id = course_id.split(':').last.strip
			name      = '???'
			url       = url.split.last
			
			# do actual processing
			SummerResearch::CatalogLink.new(course_id, name, url, 'manual')
		end
		
		
		
		
		# # NOTE: if @catalog is not set, debug_verbose() still works, but actually outputs far less data that debug()
		CourseInfoDiagnostic.debug(@catalog, data)
		# CourseInfoDiagnostic.debug_verbose(@catalog, data)
	end
	
	task :extended_set_type_signatures => "data/all_courses_2016_anomalies_types.txt" do
		@catalog = SummerResearch::Catalog.new(SQLITE_DATABASE_FILEPATH)
		
		
		# read from file
		filepath = File.expand_path(
			"./all_courses_2016_anomalies_types.txt",
			SummerResearch::Utilities::DATA_DIR
		)
		data = File.readlines(filepath)
		
		# chunk the data
		chunk_size = 3
		number_of_records = 98
		data = data.collect{ |line| line.chomp }
		           .each_slice(chunk_size).to_a
		data.pop() # remove the last entry
		
		data.each{|list| list.pop } # remove the last line of each cluster, which is just empty
		
		
		# extra processing
		data.each{|list| list.collect!{|x| x.tr('"', '')} } # remove unnecessary double quotes
		
		p data.last(3)
		
		
		# actually use the data
		out = 
			data.group_by do |name, signature|
				arr = signature.split()
				i = arr.rindex('hr')
				
				arr[0..i]
			end
		
		out.values.each{|arr| arr.collect!{|a,b| a }}
		
		puts out.to_yaml
		puts "number of types:   #{out.size}"
		puts "number of entries: #{data.size}"
		puts "#{out.size.to_f / data.size * 100}%"
	end
	
	
	
	
	# dump some course data with the expected types out of Mongo and to YAML for easy viewing
	task :sample_dump do
		@catalog = SummerResearch::Catalog.new(SQLITE_DATABASE_FILEPATH)
		
		data = 
			[
				'PSYC 320',
				'EVPP 110',
				'Mason Core UGU',
				# 'Math 551',
			].collect do |course|
				# @catalog.course_info(course, force_download: false)
				@catalog.course_info(course, force_download: true)
			end
		data.collect!{  |x| x.to_h  }
		
		SummerResearch::Utilities.write_to_file('./sample_dump.yaml', data.to_yaml)
	end
	
	
	task :group_by_type do
		# TODO: store the type of the CourseInfo object in Mongo. would make this a whole lot easier
		
		@catalog = SummerResearch::Catalog.new(SQLITE_DATABASE_FILEPATH)
		
		
		course_list = nil
		@catalog.activerecord_query do |course_model, catologyear_model|
			all_courses_in_year = 
				catologyear_model.where(:year_range => '2016-2017')
				                 .first.courses
			
			course_list = all_courses_in_year
		end
		
		
		course_list.collect!{  |x| x.to_CourseInfo()  }
		
		out = 
			course_list.group_by do |course|
				course_type = nil
				
				# === based on code copied from CourseInfo#fetch()
				
				url = course.url
				
				
				# GET THE DATA USING NOKOGIRI
				xml = Nokogiri::HTML(open(url))
				chunk = xml.css('td.block_content_popup')
					# SummerResearch::Utilities.write_to_file("./course.html", chunk)
				
				
				# === figure out where the interesting section is, and store in 'segment' variable
				list = chunk.children
				# puts list.size
				
				# list.each do |node|
				# 	puts node.class
				# 	if node.class == Nokogiri::XML::Element
				# 		# p node.name
				# 		# p node.methods
				# 		break
				# 	end
				# end
				
				i_start = list.find_index{  |x| x.name == "h1" }
				i_end   = list.find_index{  |x| x.name == "div" and x["style"] == "float: right" }
				
				
				segment = list[(i_start..i_end)]
				
				
				
				
				type_search_order = SummerResearch::CourseInfo::TYPE_SEARCH_ORDER
				
				# ---
				type_search_order.each do |type_class|
					type = type_class.new(course)
					course_type = type_class
					
					if type.signature_match?(segment)
						# when a matching signature is found...
						course_type = type_class
						p course_type
						
						break
					end
				end
				# ---
				
				
				course_type # pseudo-return for block
			end
		
		out.values.each{  |arr|  arr.collect!{|x| x.id }   }
		
		p out
	end
end


module CourseInfoDiagnostic
class << self
	# I think foo13 is just a precursor to the other ones?
	# like, really why would I ever want to run this variant?
	# It's just gonna fail to give any useful diagnostic information whatsoever
	def foo13(catalog, course_list)
		output_data = 
			course_list.collect do |course|
				puts course.id
				course_info_from_catalog_link(catalog, course).fetch
			end
		
		return output_data
	end
	
	
	# find courses that fail parsing
	# want to see some examples of the unexpected
	# 
	# prints dots to let you know something is happening
	# only prints out courses that are "weird"
	# 
	# Does basicaly the same thing as foo13, but includes extra code to help report errors.
	def debug(catalog, course_list)
		flag = true
		
		course_list.each do |course|
			begin
				course_info_from_catalog_link(catalog, course).fetch
			rescue StandardError => e
				if flag
					puts ""
					flag = false
				end
				
				puts "course id:   #{course.id}"
				puts "description: #{course.description}"
				puts "url:         #{course.url}"
				puts "Catalog Link format: #{course.link_type}"
				# throw e
				
				# output the data from the exception
				# (the program will still continue to run)
				# (resulting in all errors printed in one place)
				puts e.message
				e.backtrace.each do |line|
					puts "\t" + line
					# indent the lines of the backtrace.
					# makes it easier to see things when you start getting multiple errors
				end
				puts "=============="
				puts
				puts
			else
				flag = true
				print "."
			end
		end
		
		puts ""
	end
	
	# Like debug, but with even more debug information. 
	# 
	# most of the code in this method comes directly from 'debug()' above
	# only the method call on CouseInfo has been changed from #fetch to #test_types
	# (will show more detailed type signature information, but may supress some informative errors)
	def debug_verbose(catalog, course_list)
		flag = true
		
		course_list.each do |course|
			begin
				data = course_info_from_catalog_link(catalog, course).test_types
			rescue StandardError => e
				if flag
					puts ""
					flag = false
				end
				
				puts "course id:   #{course.id}"
				puts "description: #{course.description}"
				puts "url:         #{course.url}"
				puts "Catalog Link format: #{course.link_type}"
			else
				flag = true
			ensure
				puts "=============="
				puts
				puts
			end
		end
		
		puts ""
	end
	
	
	
	# NOTE: this connects to the SQLite DB to convert between catoid => 'catalog year'
	def course_info_from_catalog_link(catalog, catalog_link)
		course = catalog_link
		
		
		dept, course_number = SummerResearch::Catalog.parse_course_id(course.id)
		
		url = course.url
		
		catoid = SummerResearch::Catalog.catoid_from_url(url)
		# convert catoid => 'catalog year' using the data in the new Catalog class
		catalog_year = catalog.catoid_to_catalog_year(catoid)
		
		
		return SummerResearch::CourseInfo.new(dept, course_number, catalog_year, url)
	end
end
end













# prereq information only, specific format, for all classes in the 2016-2017 catalog year
# CS 330 : CS 101, CS 212
# COURSE : DEP1, DEP2
# (only show direct dependencies)
# (these numbers are only for demonstration, I don't know this is real data or not)
task :qian_hu_data do
	@catalog = SummerResearch::Catalog.new(SQLITE_DATABASE_FILEPATH)
	
	
	
	
	
	# this is kinda bad form, because you don't want to be able to call this class outside of the context of @catalog, because the database may not be created yet, or there may not be a connection, etc etc etc
	# catalog_year = SummerResearch::Catalog::CatalogYear.where(:year_range => '2016-2017')
	
	
	
	out = nil
	
	@catalog.activerecord_query do |course_model, catologyear_model|
		# === update index with ALL DEPARTMENTS for the most recent catalog year
		catalog_year = catologyear_model.where(:year_range => '2016-2017')
		
		@catalog.populate_course_index(catalog_year)
		
		
		# === fetch specific information of ALL CLASSES in the current year
		all_courses_in_year = 
			catologyear_model.where(:year_range => '2016-2017')
			                 .first.courses
		
		# p all_courses_in_year
		raise "ERROR: expected a course_model" unless all_courses_in_year.first.is_a? course_model
		
		
		# filter out the main Mason Core pages.
		# These do not have the same structure as other "real courses", and may cause problems.
		all_courses_in_year = all_courses_in_year.reject{|course| course.dept == "Mason Core"}
		
		
		
		
		# --- Try to fetch information for all courses in the desired set.
		#     If you can't process a course, just keep going, but log some error data.
		#     This error log can be examined later to determine new CatalogInfo Types.
		# TODO: would be nice if you could have some sort of progress indicator for this.
		out = nil
		
		filepath = File.expand_path(
			'./all_courses_2016_new_catalog_info_types.txt',
			SummerResearch::Utilities::DATA_DIR
		)
		File.open(filepath, 'a') do |f|
			out = 
				all_courses_in_year.collect do |course_record|			
					begin
						@catalog.fetch_course_info(course_record)
					rescue StandardError => e
						f.puts "course id:   #{course_record.course_id}"
						# TODO: Add short description to index
						# f.puts "description: #{course.description}"
						f.puts "url:         #{course_record.url}"
						
						# output the data from the exception
						# (the program will still continue to run)
						# (resulting in all errors printed in one place)
						f.puts e.message
						e.backtrace.each do |line|
							f.puts "\t" + line
							# indent the lines of the backtrace.
							# makes it easier to see things when you start getting multiple errors
						end
						f.puts "=============="
						f.puts
						f.puts
					end
				end
		end
	end
	
	# raise "ERROR: Not all course info types recognized. Define new types and try again." if out.include? nil
	
	main_requirements = out.compact
	
	
	
	# === parse direct prereqs for each and every class
	p main_requirements.collect{  |course_info| course_info.id  }
	data = 
		main_requirements.uniq.collect do |course_info|
			name = course_info.id
			
			puts "-=-=-=-=-=-=-=-="
			
			deps = course_info["Prerequisite(s)"]
				puts "=>  #{deps.inspect}"
			deps = deps.nil? ? [] : parse_dependencies(deps)
				puts "=>  #{deps.inspect}"
			deps = [] if deps.nil?
				puts "=>  #{deps.inspect}"
			
			# oooh yeah. parse_dependencies can return nil, even if the dependecies field is set
				# ex) CS 499 => "60 credits and permission of instructor; specific prerequisites vary with nature of topic."
			
			
			raise "ERROR: #{course_info.id} => #{deps.inspect} "if deps.nil? or deps == ''
			
			[name, deps]
		end
	p data
	
	# === convert to desired output format
	filepath = File.expand_path('./qian_sample_5.txt', SummerResearch::Utilities::DATA_DIR)
	File.open(filepath, 'a') do |f|
		data.each do |name, deps|
			name = name.tr(' ', '-')
			deps.collect!{  |x| x.tr(' ', '-')  }
			
			
			f.puts "#{name}:#{deps.join(',')}"
		end
	end
	
end



# all Mongo data in CSV format
task :thi_data do
	@mongo_ip      = "127.0.0.1"
	@mongo_port    = "12345"
	@mongo_address = [@mongo_ip, @mongo_port].join(':')
	@mongo = Mongo::Client.new([ @mongo_address ], :database => 'mydb')
	
	
	@mongo[:course_info].tap do |mongo|
		courses_from_this_year = 
			mongo.find(
					:catalog_year => "2016-2017"
				).sort(
					:course_id => 1 # 1 or -1 to control the order
				)
		
		course_info_list = 
			courses_from_this_year.collect do |mongo_bson|
				SummerResearch::CourseInfo.load(mongo_bson)
			end
		
		
		puts "data points: #{course_info_list.size}"
		course_info_list.each do |info|
			# info.to_h.keys
		end
		
		
		possible_keys = courses_from_this_year.collect{ |info|  info.to_h.keys }.flatten.uniq
		possible_keys.delete "_id" # Mongo-specific key
		possible_keys.delete "type" # depreciated key
		p possible_keys
		
		
		# first row lists the schema, each other row lists values
		# NOTE: the number of rows in the text file is not equal to the number of CSV rows, because of multi-line strings.
		
		data = 
			CSV.generate do |csv|
				csv << possible_keys
				
				courses_from_this_year.each do |info|
					# p info
					info["Description"].strip!
					
					row = possible_keys.collect{|k| info[k]}
					csv << row
					
				end
			end
		
		SummerResearch::Utilities.write_to_file("./thi_data_csv.csv", data)
		
		
		
		
		
		
		
		
		
		
		filepath = "/home/ravenskrag/Work/Rangwalla Summer NSF/Work/SummerResearch2016/web_app/models/CS_BS/data/CS_BS_requirements_by_type.yaml"
		requirements = YAML.load_file filepath
		
		categories = [:required, :elective].collect{  |type|  requirements[type] }
		
		requ_data, elec_data = 
			categories.collect do |category|
				p category
				
				CSV.generate do |csv|
					csv << possible_keys
					
					puts "==========="
					p courses_from_this_year.to_a.first['course_id']
					puts "==========="
					
					courses_from_this_year.to_a
					.select{  |info|  category.include? info["course_id"]  }
					.each do |info|
						# p info
						info["Description"].strip!
						
						row = possible_keys.collect{|k| info[k]}
						csv << row
						
					end
				end
			end
		
		
		SummerResearch::Utilities.write_to_file("./thi_data_csv_required.csv", requ_data)
		SummerResearch::Utilities.write_to_file("./thi_data_csv_elective.csv", elec_data)
	end
end


